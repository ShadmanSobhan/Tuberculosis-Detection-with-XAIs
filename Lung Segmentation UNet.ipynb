{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":258315,"sourceType":"datasetVersion","datasetId":108201},{"sourceId":2332307,"sourceType":"datasetVersion","datasetId":891819},{"sourceId":8822211,"sourceType":"datasetVersion","datasetId":5307453},{"sourceId":8822698,"sourceType":"datasetVersion","datasetId":5307799},{"sourceId":8916681,"sourceType":"datasetVersion","datasetId":5362430},{"sourceId":8947057,"sourceType":"datasetVersion","datasetId":5384087},{"sourceId":8950071,"sourceType":"datasetVersion","datasetId":5386055},{"sourceId":8974100,"sourceType":"datasetVersion","datasetId":5403040},{"sourceId":9050651,"sourceType":"datasetVersion","datasetId":5456937}],"dockerImageVersionId":20479,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Replace 'path/to/image.png' with the actual path where you downloaded the image\nimage = plt.imread('/kaggle/working/4200mask/Tuberculosis/Tuberculosis-397.png')\nplt.imshow(image)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Define the source and destination directories\nsource_dir = '/kaggle/input/azteunet'\ndestination_dir = '/kaggle/working/data'\n\n# Move the folder\ntry:\n    shutil.copy(source_dir, destination_dir)\n    print(f\"Kaggle folder moved from {source_dir} to {destination_dir}\")\nexcept Exception as e:\n    print(f\"Error moving Kaggle folder: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the source and destination folders in Kaggle\nsource_folder = '/kaggle/input/azteunet/masks'\ndestination_folder = '/kaggle/working/jsrt/masks'\n\n# Create the destination folder if it doesn't exist\n# os.makedirs(destination_folder, exist_ok=True)\n\n# Copy all files from source to destination\nfor file_name in os.listdir(source_folder):\n    full_file_name = os.path.join(source_folder, file_name)\n    if os.path.isfile(full_file_name):\n        shutil.copy(full_file_name, destination_folder)\n\nprint(\"All files have been copied successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Data Augmentation**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom PIL import Image\n\n# Define the folders\noriginal_image_folder = '/kaggle/working/jsrt/cxr'\nthreshold_image_folder = '/kaggle/working/jsrt/threshold'\nmask_image_folder = '/kaggle/working/jsrt/masks'\naugmented_original_folder = '/kaggle/working/jsrtaug/cxr'\naugmented_threshold_folder = '/kaggle/working/jsrtaug/threshold'\naugmented_mask_folder = '/kaggle/working/jsrtaug/masks'\n\n# Create the folders if they don't exist\nos.makedirs(augmented_original_folder, exist_ok=True)\nos.makedirs(augmented_threshold_folder, exist_ok=True)\nos.makedirs(augmented_mask_folder, exist_ok=True)\n\n# Define the data augmentation parameters\ndatagen = ImageDataGenerator(\n    zoom_range=0.2,\n    rotation_range=3\n)\n\ndef save_augmented_image(image_array, save_folder, image_name, counter):\n    aug_image = array_to_img(image_array[0])\n    aug_image = aug_image.convert('L')  # Convert to grayscale\n    base_name, ext = os.path.splitext(image_name)\n    new_image_name = f\"{base_name}_{counter}{ext}\"\n    aug_image.save(os.path.join(save_folder, new_image_name))\n\ndef augment_and_save_images(image_name, num_augments=3):\n    # Load the images\n    original_img_path = os.path.join(original_image_folder, image_name)\n    threshold_img_path = os.path.join(threshold_image_folder, image_name)\n    mask_img_path = os.path.join(mask_image_folder, image_name)\n    \n    original_img = load_img(original_img_path).convert('L')  # Convert to grayscale\n    threshold_img = load_img(threshold_img_path).convert('L')  # Convert to grayscale\n    mask_img = load_img(mask_img_path).convert('L')  # Convert to grayscale\n    \n    original_x = img_to_array(original_img)\n    threshold_x = img_to_array(threshold_img)\n    mask_x = img_to_array(mask_img)\n    \n    original_x = np.expand_dims(original_x, axis=0)\n    threshold_x = np.expand_dims(threshold_x, axis=0)\n    mask_x = np.expand_dims(mask_x, axis=0)\n    \n    # Augment the images and save\n    counter = 0\n    seed = np.random.randint(10000)  # Generate a random seed for consistent transformations\n    for i in range(num_augments):\n        for batch in datagen.flow(original_x, batch_size=1, seed=seed):\n            save_augmented_image(batch, augmented_original_folder, image_name, counter)\n            break\n        for batch in datagen.flow(threshold_x, batch_size=1, seed=seed):\n            save_augmented_image(batch, augmented_threshold_folder, image_name, counter)\n            break\n        for batch in datagen.flow(mask_x, batch_size=1, seed=seed):\n            save_augmented_image(batch, augmented_mask_folder, image_name, counter)\n            break\n        counter += 1\n\n# Get the list of image names\nimage_names = os.listdir(original_image_folder)\n\n# Apply augmentation to each set of images\nfor image_name in image_names:\n    augment_and_save_images(image_name, num_augments=3)\n\ndef show_images_with_same_name(image_names, title):\n    plt.figure(figsize=(30, 10))\n    for i, image_name in enumerate(image_names):\n        base_name, ext = os.path.splitext(image_name)\n        for j in range(3):  # Display the first 3 augmentations\n            aug_original_img_path = os.path.join(augmented_original_folder, f\"{base_name}_{j}{ext}\")\n            aug_threshold_img_path = os.path.join(augmented_threshold_folder, f\"{base_name}_{j}{ext}\")\n            aug_mask_img_path = os.path.join(augmented_mask_folder, f\"{base_name}_{j}{ext}\")\n            \n            aug_original_img = load_img(aug_original_img_path)\n            aug_threshold_img = load_img(aug_threshold_img_path)\n            aug_mask_img = load_img(aug_mask_img_path)\n            \n            plt.subplot(len(image_names), 9, i * 9 + j * 3 + 1)\n            plt.imshow(aug_original_img, cmap='gray')\n            plt.title(f'{image_name} - Original_{j}')\n            plt.axis('off')\n            \n            plt.subplot(len(image_names), 9, i * 9 + j * 3 + 2)\n            plt.imshow(aug_threshold_img, cmap='gray')\n            plt.title(f'{image_name} - Threshold_{j}')\n            plt.axis('off')\n            \n            plt.subplot(len(image_names), 9, i * 9 + j * 3 + 3)\n            plt.imshow(aug_mask_img, cmap='gray')\n            plt.title(f'{image_name} - Mask_{j}')\n            plt.axis('off')\n    plt.suptitle(title)\n    plt.show()\n\n# Display the first 3 sets of 3 augmented images\nshow_images_with_same_name(image_names[:3], 'Augmented Images with Same Name and Incremented Variable')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nsize=(224, 224)\n\n# Read the image in grayscale\nimage = cv2.imread('/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-500.png', cv2.IMREAD_GRAYSCALE)\n\n# Apply CLAHE to enhance local contrast\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\nenhanced_image = clahe.apply(image)\n\n# Resize the image\nresized_image = cv2.resize(enhanced_image, size, interpolation=cv2.INTER_AREA)\n\n# Generate the threshold image\n_, threshold_image = cv2.threshold(resized_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\n# Plot the original grayscale image\nplt.subplot(131)  # Create a subplot at position 1,2 (1st row, 2nd column)\nplt.imshow(image, cmap='gray')  # Plot grayscale image with 'gray' colormap\nplt.title('Original Grayscale Image')\nplt.axis('off')  # Hide axes for cleaner plot\n\n# Plot the enhanced image\nplt.subplot(132)  # Create a subplot at position 1,2 (1st row, 2nd column)\nplt.imshow(enhanced_image, cmap='gray')  # Plot grayscale image with 'gray' colormap\nplt.title('Enhanced Image (CLAHE)')\nplt.axis('off')  # Hide axes for cleaner plot\n\n# Plot the enhanced image\nplt.subplot(133)  # Create a subplot at position 1,2 (1st row, 2nd column)\nplt.imshow(threshold_image, cmap='gray')  # Plot grayscale image with 'gray' colormap\nplt.title('Threshold Image')\nplt.axis('off')  # Hide axes for cleaner plot\n\n# Show the plots\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nfrom tqdm import tqdm\n\n# Paths to the input, output, and threshold directories\ninput_dir = '/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis'\noutput_dir = '/kaggle/working/tb4200/cxr'\nthreshold_dir = '/kaggle/working/tb4200/threshold'\n\n# Ensure output and threshold directories exist\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(threshold_dir, exist_ok=True)\n\n# Function to apply CLAHE, resize, generate threshold image, and save\ndef enhance_resize_threshold_and_save(image_path, output_dir, threshold_dir, size=(224, 224)):\n    # Read the image in grayscale\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n    # Apply CLAHE to enhance local contrast\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    enhanced_image = clahe.apply(image)\n\n    # Resize the image\n    resized_image = cv2.resize(enhanced_image, size, interpolation=cv2.INTER_AREA)\n\n    # Generate the threshold image\n    _, threshold_image = cv2.threshold(resized_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\n    # Save the enhanced image\n    filename = os.path.basename(image_path)\n    enhanced_output_path = os.path.join(output_dir, filename)\n    cv2.imwrite(enhanced_output_path, resized_image)\n\n    # Save the threshold image\n    threshold_output_path = os.path.join(threshold_dir, filename)\n    cv2.imwrite(threshold_output_path, threshold_image)\n\n# Get list of all image files in the input directory\nimage_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n\n# Process each image file with progress tracking\nfor image_file in tqdm(image_files, desc=\"Processing images\"):\n    enhance_resize_threshold_and_save(image_file, output_dir, threshold_dir)\n\nprint(\"Enhanced, resized, and threshold images are saved to their respective directories.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:32:12.147193Z","iopub.execute_input":"2024-08-03T15:32:12.147482Z","iopub.status.idle":"2024-08-03T15:32:26.508525Z","shell.execute_reply.started":"2024-08-03T15:32:12.147438Z","shell.execute_reply":"2024-08-03T15:32:26.507656Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nfrom tqdm import tqdm\n\n# Define the input and output directories\ninput_dir = '/kaggle/input/jsrt-247-image-lung-segmentation-mask-dataset/content/jsrt/masks'\noutput_dir = '/kaggle/working/jsrt/masks'\n\n# Ensure the output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Function to resize and convert to grayscale\ndef resize_and_convert_to_grayscale(image_path, output_dir, size=(224, 224)):\n    # Read the image\n    image = cv2.imread(image_path)\n    \n    # Convert to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Resize the image\n    resized_image = cv2.resize(gray_image, size, interpolation=cv2.INTER_AREA)\n\n    # Save the processed image\n    filename = os.path.basename(image_path)\n    output_path = os.path.join(output_dir, filename)\n    cv2.imwrite(output_path, resized_image)\n\n# Get list of all image files in the input directory\nimage_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n\n# Process each image file with progress tracking\nfor image_file in tqdm(image_files, desc=\"Processing images\"):\n    resize_and_convert_to_grayscale(image_file, output_dir)\n\nprint(\"All images have been resized, converted to grayscale, and saved to the output directory.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef list_files(folder):\n    \"\"\"Returns a set of file names in the given folder.\"\"\"\n    return set(os.listdir(folder))\n\ndef find_missing_files(folder1, folder2):\n    \"\"\"Finds files in folder1 that are not present in folder2.\"\"\"\n    files1 = list_files(folder1)\n    files2 = list_files(folder2)\n    missing_files = files1 - files2\n    return missing_files\n\n\n\n\n\n# Example usage\nfolder1 = '/kaggle/input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png'\nfolder2 = '/kaggle/input/azteunet/enhanced_images'\n\nmissing_files = find_missing_files(folder1, folder2)\n\n\nprint(len(missing_files))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prompt: check total image of folders\n\nimport os\n\n# Get the list of folders\nfolders = ['/kaggle/working/jsrtaug/cxr', '/kaggle/working/jsrtaug/threshold', '/kaggle/working/jsrtaug/masks', ]\n\n# Iterate over the folders and count the number of images\nfor folder in folders:\n    image_count = len(os.listdir(folder))\n    print(f\"Total images in {folder}: {image_count}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Specify the path to the folder you want to delete\nfolder_path = '/kaggle/working/4200'\n\n# Remove the folder and all its contents\nshutil.rmtree(folder_path)\n\nprint(f\"Folder '{folder_path}' has been removed.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Define the directory containing the files to rename\ndirectory = '/kaggle/working/shenmon/masks'\n\n# Iterate over all files in the directory\nfor filename in os.listdir(directory):\n    # Check if the file ends with '_mask.png'\n    if filename.endswith('_mask.png'):\n        # Create the new filename by replacing '_mask.png' with '.png'\n        new_filename = filename.replace('_mask.png', '.png')\n        # Get the full path to the old and new filenames\n        old_file = os.path.join(directory, filename)\n        new_file = os.path.join(directory, new_filename)\n        # Rename the file\n        os.rename(old_file, new_file)\n\nprint(\"All files have been renamed.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Define the directories\nsource_dir = '/kaggle/working/shenmiss/threshold'\nreference_dir = '/kaggle/input/azteunet/enhanced_images'\n\n# Get the set of filenames (without extension) from the reference directory\nreference_files = {os.path.splitext(f)[0] for f in os.listdir(reference_dir) if os.path.isfile(os.path.join(reference_dir, f))}\n\n# Iterate over all files in the source directory\nfor filename in os.listdir(source_dir):\n    if os.path.isfile(os.path.join(source_dir, filename)):\n        # Get the base name without extension\n        base_name = os.path.splitext(filename)[0]\n        \n        # Check if the base name exists in the reference directory\n        if base_name not in reference_files:\n            # If not, delete the file from the source directory\n            os.remove(os.path.join(source_dir, filename))\n            print(f\"Deleted: {filename}\")\n\nprint(\"Files that do not have a corresponding file in the reference directory have been deleted.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Specify the folder you want to zip and the output zip file name\nfolder_path = '/kaggle/working/data'\noutput_zip = '/kaggle/working/data.zip'\n\n# Create a zip archive\nshutil.make_archive(output_zip, 'zip', folder_path)\n\nprint(f\"Folder '{folder_path}' has been zipped to '{output_zip}.zip'.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import numpy as np\n# from PIL import Image\n# from tensorflow.keras.utils import Sequence\n\n# class DataGenerator(Sequence):\n#     def __init__(self, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=32, target_size=(224, 224)):\n#         self.original_image_folder = original_image_folder\n#         self.threshold_image_folder = threshold_image_folder\n#         self.mask_image_folder = mask_image_folder\n#         self.batch_size = batch_size\n#         self.target_size = target_size\n\n#         self.original_filenames = sorted(os.listdir(self.original_image_folder))\n#         self.threshold_filenames = sorted(os.listdir(self.threshold_image_folder))\n#         self.mask_filenames = sorted(os.listdir(self.mask_image_folder))\n\n#     def __len__(self):\n#         return int(np.ceil(len(self.original_filenames) / self.batch_size))\n\n#     def __getitem__(self, idx):\n#         batch_original_filenames = self.original_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         batch_threshold_filenames = self.threshold_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         batch_mask_filenames = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n#         original_images = np.zeros((self.batch_size, *self.target_size, 1))\n#         threshold_images = np.zeros((self.batch_size, *self.target_size, 1))\n#         mask_images = np.zeros((self.batch_size, *self.target_size, 1))\n\n#         for i, filename in enumerate(batch_original_filenames):\n#             original_path = os.path.join(self.original_image_folder, filename)\n#             threshold_path = os.path.join(self.threshold_image_folder, batch_threshold_filenames[i])\n#             mask_path = os.path.join(self.mask_image_folder, batch_mask_filenames[i])\n\n#             original_img = Image.open(original_path).convert('L').resize(self.target_size)\n#             threshold_img = Image.open(threshold_path).convert('L').resize(self.target_size)\n#             mask_img = Image.open(mask_path).convert('L').resize(self.target_size)\n\n#             original_img = np.array(original_img) / 255.0\n#             threshold_img = np.array(threshold_img) / 255.0\n#             mask_img = np.array(mask_img) / 255.0\n\n#             original_images[i, :, :, 0] = original_img\n#             threshold_images[i, :, :, 0] = threshold_img\n#             mask_images[i, :, :, 0] = mask_img\n\n#         return [original_images, threshold_images], mask_images\n\n# # Paths to the datasets\n# original_image_folder = '/kaggle/working/jsrtaug/cxr'\n# threshold_image_folder = '/kaggle/working/jsrtaug/threshold'\n# mask_image_folder = '/kaggle/working/jsrtaug/masks'\n\n# # Create the DataGenerator instances\n# train_generator = DataGenerator(original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n# val_generator = DataGenerator(original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n\n# # Plot images from the first batch\n# import matplotlib.pyplot as plt\n\n# def plot_images(generator):\n#     [original_images, threshold_images], mask_images = next(iter(generator))\n    \n#     print(original_images.shape)\n#     print(threshold_images.shape)\n#     print(mask_images.shape)\n#     plt.figure(figsize=(12, 12))\n    \n#     for i in range(4):\n#         # Original image\n#         plt.subplot(4, 3, i * 3 + 1)\n#         plt.imshow(original_images[i, :, :, 0], cmap='gray')\n#         plt.title('Original')\n#         plt.axis('off')\n        \n#         # Threshold image\n#         plt.subplot(4, 3, i * 3 + 2)\n#         plt.imshow(threshold_images[i, :, :, 0], cmap='gray')\n#         plt.title('Threshold')\n#         plt.axis('off')\n        \n#         # Mask image\n#         plt.subplot(4, 3, i * 3 + 3)\n#         plt.imshow(mask_images[i, :, :, 0], cmap='gray')\n#         plt.title('Mask')\n#         plt.axis('off')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# # Plot the first batch of images\n# plot_images(train_generator)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Data Generator (Needed)**","metadata":{}},{"cell_type":"markdown","source":"**Data generator with augmentation**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image, ImageEnhance\nfrom tensorflow.keras.utils import Sequence\nimport random\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nclass DataGenerator(Sequence):\n    def __init__(self, original_filenames, threshold_filenames, mask_filenames, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=32, target_size=(224, 224), augment=False):\n        self.original_filenames = original_filenames\n        self.threshold_filenames = threshold_filenames\n        self.mask_filenames = mask_filenames\n        self.original_image_folder = original_image_folder\n        self.threshold_image_folder = threshold_image_folder\n        self.mask_image_folder = mask_image_folder\n        self.batch_size = batch_size\n        self.target_size = target_size\n        self.augment = augment\n\n    def __len__(self):\n        return int(np.ceil(len(self.original_filenames) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_original_filenames = self.original_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_threshold_filenames = self.threshold_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_mask_filenames = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        original_images = np.zeros((self.batch_size, *self.target_size, 1))\n        threshold_images = np.zeros((self.batch_size, *self.target_size, 1))\n        mask_images = np.zeros((self.batch_size, *self.target_size, 1))\n\n        for i, filename in enumerate(batch_original_filenames):\n            original_path = os.path.join(self.original_image_folder, filename)\n            threshold_path = os.path.join(self.threshold_image_folder, batch_threshold_filenames[i])\n            mask_path = os.path.join(self.mask_image_folder, batch_mask_filenames[i])\n\n            original_img = Image.open(original_path).convert('L').resize(self.target_size, Image.LANCZOS)\n            threshold_img = Image.open(threshold_path).convert('L').resize(self.target_size, Image.LANCZOS)\n            mask_img = Image.open(mask_path).convert('L').resize(self.target_size, Image.LANCZOS)\n\n            if self.augment:\n                original_img, threshold_img, mask_img = self.apply_augmentation(original_img, threshold_img, mask_img)\n\n            original_img = np.array(original_img) / 255.0\n            threshold_img = np.array(threshold_img) / 255.0\n            mask_img = np.array(mask_img) / 255.0\n\n            original_images[i, :, :, 0] = original_img\n            threshold_images[i, :, :, 0] = threshold_img\n            mask_images[i, :, :, 0] = mask_img\n\n        return [original_images, threshold_images], mask_images\n\n    def apply_augmentation(self, original_img, threshold_img, mask_img):\n        # Random rotation\n        if random.random() > 0.5:\n            angle = random.uniform(-15, 15)\n            original_img = original_img.rotate(angle)\n            threshold_img = threshold_img.rotate(angle)\n            mask_img = mask_img.rotate(angle)\n\n        # Random zoom\n        if random.random() > 0.5:\n            scale = random.uniform(0.8, 1.2)\n            w, h = original_img.size\n            new_w, new_h = int(w * scale), int(h * scale)\n            original_img = original_img.resize((new_w, new_h), Image.LANCZOS)\n            threshold_img = threshold_img.resize((new_w, new_h), Image.LANCZOS)\n            mask_img = mask_img.resize((new_w, new_h), Image.LANCZOS)\n\n            # Center crop to original size\n            left = (new_w - w) // 2\n            top = (new_h - h) // 2\n            original_img = original_img.crop((left, top, left + w, top + h))\n            threshold_img = threshold_img.crop((left, top, left + w, top + h))\n            mask_img = mask_img.crop((left, top, left + w, top + h))\n\n        # Random crop\n        if random.random() > 0.5:\n            crop_size = random.uniform(0.8, 1.0)\n            w, h = original_img.size\n            new_w, new_h = int(w * crop_size), int(h * crop_size)\n            left = random.randint(0, w - new_w)\n            top = random.randint(0, h - new_h)\n            original_img = original_img.crop((left, top, left + new_w, top + new_h))\n            threshold_img = threshold_img.crop((left, top, left + new_w, top + new_h))\n            mask_img = mask_img.crop((left, top, left + new_w, top + new_h))\n\n            # Resize back to original size\n            original_img = original_img.resize((w, h), Image.LANCZOS)\n            threshold_img = threshold_img.resize((w, h), Image.LANCZOS)\n            mask_img = mask_img.resize((w, h), Image.LANCZOS)\n\n        # Random brightness adjustment\n        if random.random() > 0.5:\n            enhancer = ImageEnhance.Brightness(original_img)\n            original_img = enhancer.enhance(random.uniform(0.8, 1.2))\n            enhancer = ImageEnhance.Brightness(threshold_img)\n            threshold_img = enhancer.enhance(random.uniform(0.8, 1.2))\n\n        # Random contrast adjustment\n        if random.random() > 0.5:\n            enhancer = ImageEnhance.Contrast(original_img)\n            original_img = enhancer.enhance(random.uniform(0.8, 1.2))\n            enhancer = ImageEnhance.Contrast(threshold_img)\n            threshold_img = enhancer.enhance(random.uniform(0.8, 1.2))\n\n        return original_img, threshold_img, mask_img\n\n# Paths to the datasets\noriginal_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/cxr'\nthreshold_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/threshold'\nmask_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/masks'\n\n# Get the list of filenames\noriginal_filenames = sorted(os.listdir(original_image_folder))\nthreshold_filenames = sorted(os.listdir(threshold_image_folder))\nmask_filenames = sorted(os.listdir(mask_image_folder))\n\n# Split the data into training (80%) and test (20%) sets\ntrain_original, test_original, train_threshold, test_threshold, train_mask, test_mask = train_test_split(\n    original_filenames, threshold_filenames, mask_filenames, test_size=0.2, random_state=42)\n\n# Split the training set further into training (80%) and validation (20%) sets\n# train_original, val_original, train_threshold, val_threshold, train_mask, val_mask = train_test_split(\n#     train_original, train_threshold, train_mask, test_size=0.2, random_state=42)\n\n# Create the DataGenerator instances with the split datasets\n# train_generator = DataGenerator(train_original, train_threshold, train_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16, augment=True)\n# val_generator = DataGenerator(val_original, val_threshold, val_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\ntest_generator = DataGenerator(test_original, test_threshold, test_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n\n# Plot images from the first batch\ndef plot_images(generator):\n    [original_images, threshold_images], mask_images = next(iter(generator))\n    \n    print(original_images.shape)\n    print(threshold_images.shape)\n    print(mask_images.shape)\n    plt.figure(figsize=(12, 12))\n    \n    for i in range(4):\n        # Original image\n        plt.subplot(4, 3, i * 3 + 1)\n        plt.imshow(original_images[i, :, :, 0], cmap='gray')\n        plt.title('Original')\n        plt.axis('off')\n        \n        # Threshold image\n        plt.subplot(4, 3, i * 3 + 2)\n        plt.imshow(threshold_images[i, :, :, 0], cmap='gray')\n        plt.title('Threshold')\n        plt.axis('off')\n        \n        # Mask image\n        plt.subplot(4, 3, i * 3 + 3)\n        plt.imshow(mask_images[i, :, :, 0], cmap='gray')\n        plt.title('Mask')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plot the first batch of images with augmentation\nplot_images(test_generator)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import numpy as np\n# from PIL import Image\n# from tensorflow.keras.utils import Sequence\n# from keras.preprocessing.image import ImageDataGenerator, img_to_array\n# import matplotlib.pyplot as plt\n# from sklearn.model_selection import train_test_split\n\n# class DataGenerator(Sequence):\n#     def __init__(self, original_filenames, threshold_filenames, mask_filenames, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=32, target_size=(224, 224), augment=False):\n#         self.original_filenames = original_filenames\n#         self.threshold_filenames = threshold_filenames\n#         self.mask_filenames = mask_filenames\n#         self.original_image_folder = original_image_folder\n#         self.threshold_image_folder = threshold_image_folder\n#         self.mask_image_folder = mask_image_folder\n#         self.batch_size = batch_size\n#         self.target_size = target_size\n#         self.augment = augment\n        \n#         if self.augment:\n#             self.datagen = ImageDataGenerator(\n#                 zoom_range=0.2,\n#                 rotation_range=3\n#             )\n\n#     def __len__(self):\n#         return int(np.ceil(len(self.original_filenames) / self.batch_size))\n\n#     def __getitem__(self, idx):\n#         batch_original_filenames = self.original_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         batch_threshold_filenames = self.threshold_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         batch_mask_filenames = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n#         original_images = np.zeros((self.batch_size, *self.target_size, 1))\n#         threshold_images = np.zeros((self.batch_size, *self.target_size, 1))\n#         mask_images = np.zeros((self.batch_size, *self.target_size, 1))\n\n#         for i, filename in enumerate(batch_original_filenames):\n#             original_path = os.path.join(self.original_image_folder, filename)\n#             threshold_path = os.path.join(self.threshold_image_folder, batch_threshold_filenames[i])\n#             mask_path = os.path.join(self.mask_image_folder, batch_mask_filenames[i])\n\n#             original_img = Image.open(original_path).convert('L').resize(self.target_size, Image.LANCZOS)\n#             threshold_img = Image.open(threshold_path).convert('L').resize(self.target_size, Image.LANCZOS)\n#             mask_img = Image.open(mask_path).convert('L').resize(self.target_size, Image.LANCZOS)\n\n#             if self.augment:\n#                 original_img, threshold_img, mask_img = self.apply_augmentation(original_img, threshold_img, mask_img)\n\n#             original_img = np.array(original_img) / 255.0\n#             threshold_img = np.array(threshold_img) / 255.0\n#             mask_img = np.array(mask_img) / 255.0\n\n#             original_images[i, :, :, 0] = original_img\n#             threshold_images[i, :, :, 0] = threshold_img\n#             mask_images[i, :, :, 0] = mask_img\n\n#         return [original_images, threshold_images], mask_images\n\n#     def apply_augmentation(self, original_img, threshold_img, mask_img):\n#         seed = np.random.randint(10000)\n        \n#         original_x = np.expand_dims(img_to_array(original_img), axis=0)\n#         threshold_x = np.expand_dims(img_to_array(threshold_img), axis=0)\n#         mask_x = np.expand_dims(img_to_array(mask_img), axis=0)\n\n#         original_img_aug = self.datagen.flow(original_x, batch_size=1, seed=seed)[0][0]\n#         threshold_img_aug = self.datagen.flow(threshold_x, batch_size=1, seed=seed)[0][0]\n#         mask_img_aug = self.datagen.flow(mask_x, batch_size=1, seed=seed)[0][0]\n\n#         # Convert back to PIL Image and ensure single channel\n#         original_img_aug = Image.fromarray(original_img_aug.astype('uint8').squeeze())\n#         threshold_img_aug = Image.fromarray(threshold_img_aug.astype('uint8').squeeze())\n#         mask_img_aug = Image.fromarray(mask_img_aug.astype('uint8').squeeze())\n\n#         return original_img_aug, threshold_img_aug, mask_img_aug\n\n# # Paths to the datasets\n# original_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/cxr'\n# threshold_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/threshold'\n# mask_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/masks'\n\n# # Get the list of filenames\n# original_filenames = sorted(os.listdir(original_image_folder))\n# threshold_filenames = sorted(os.listdir(threshold_image_folder))\n# mask_filenames = sorted(os.listdir(mask_image_folder))\n\n# # Split the data into training (80%) and test (20%) sets\n# train_original, test_original, train_threshold, test_threshold, train_mask, test_mask = train_test_split(\n#     original_filenames, threshold_filenames, mask_filenames, test_size=0.2, random_state=42)\n\n# # Split the training set further into training (80%) and validation (20%) sets\n# train_original, val_original, train_threshold, val_threshold, train_mask, val_mask = train_test_split(\n#     train_original, train_threshold, train_mask, test_size=0.2, random_state=42)\n\n# # Create the DataGenerator instances with the split datasets\n# train_generator = DataGenerator(train_original, train_threshold, train_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16, augment=True)\n# val_generator = DataGenerator(val_original, val_threshold, val_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n# test_generator = DataGenerator(test_original, test_threshold, test_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n\n# # Plot images from the first batch\n# def plot_images(generator):\n#     [original_images, threshold_images], mask_images = next(iter(generator))\n    \n#     print(original_images.shape)\n#     print(threshold_images.shape)\n#     print(mask_images.shape)\n#     plt.figure(figsize=(12, 12))\n    \n#     for i in range(4):\n#         # Original image\n#         plt.subplot(4, 3, i * 3 + 1)\n#         plt.imshow(original_images[i, :, :, 0], cmap='gray')\n#         plt.title('Original')\n#         plt.axis('off')\n        \n#         # Threshold image\n#         plt.subplot(4, 3, i * 3 + 2)\n#         plt.imshow(threshold_images[i, :, :, 0], cmap='gray')\n#         plt.title('Threshold')\n#         plt.axis('off')\n        \n#         # Mask image\n#         plt.subplot(4, 3, i * 3 + 3)\n#         plt.imshow(mask_images[i, :, :, 0], cmap='gray')\n#         plt.title('Mask')\n#         plt.axis('off')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# # Plot the first batch of images with augmentation\n# plot_images(train_generator)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\n\n# Path to the input directory\ninput_dir = '/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal'\n\n# Path to the output directory\noutput_dir = '/kaggle/working//TB_Norm_Enhanced'\n\n# Ensure output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Function to apply CLAHE and save the image\ndef enhance_and_save(image_path, output_dir):\n    # Read the image\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n    # Apply CLAHE to enhance local contrast\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    enhanced_image = clahe.apply(image)\n\n    # Save the result\n    filename = os.path.basename(image_path)\n    output_path = os.path.join(output_dir, filename)\n    cv2.imwrite(output_path, enhanced_image)\n\n# Get list of all image files in the input directory\nimage_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n\n# Process each image file\nfor image_file in image_files:\n    enhance_and_save(image_file, output_dir)\n\nprint(\"Enhanced images are saved to the output directory.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nfolder_path = '/kaggle/working//CXR_enhanced'\nzip_path = '/kaggle/working//CXR_enhanced.zip'\n\n# Create a zip archive of the specified folder\nshutil.make_archive(zip_path.replace('.zip', ''), 'zip', folder_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = output_dir","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.__version__","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model (Needed)**","metadata":{}},{"cell_type":"markdown","source":"best below","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\n\ndef conv_block(input_tensor, num_filters):\n    x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(input_tensor)\n    x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n    return x\n\ndef unet_plus_plus(input_shape):\n    base_input = Input(shape=input_shape, name=\"base_input\")\n    threshold_input = Input(shape=input_shape, name=\"threshold_input\")\n\n    # First few layers using only base input\n    x0_0 = conv_block(base_input, 64)\n    x1_0 = conv_block(MaxPooling2D((2, 2))(x0_0), 128)\n    x2_0 = conv_block(MaxPooling2D((2, 2))(x1_0), 256)\n\n    # Introducing the threshold input later\n    x2_0 = concatenate([x2_0, MaxPooling2D((4, 4))(threshold_input)], axis=-1)\n\n    # Continue with the UNet++ structure\n    x3_0 = conv_block(MaxPooling2D((2, 2))(x2_0), 512)\n    x4_0 = conv_block(MaxPooling2D((2, 2))(x3_0), 1024)\n\n    x0_1 = conv_block(concatenate([x0_0, Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x1_0)]), 64)\n    x1_1 = conv_block(concatenate([x1_0, Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x2_0)]), 128)\n    x2_1 = conv_block(concatenate([x2_0, Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x3_0)]), 256)\n    x3_1 = conv_block(concatenate([x3_0, Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x4_0)]), 512)\n\n    x0_2 = conv_block(concatenate([x0_0, x0_1, Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x1_1)]), 64)\n    x1_2 = conv_block(concatenate([x1_0, x1_1, Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x2_1)]), 128)\n    x2_2 = conv_block(concatenate([x2_0, x2_1, Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x3_1)]), 256)\n\n    x0_3 = conv_block(concatenate([x0_0, x0_1, x0_2, Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x1_2)]), 64)\n    x1_3 = conv_block(concatenate([x1_0, x1_1, x1_2, Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x2_2)]), 128)\n\n    x0_4 = conv_block(concatenate([x0_0, x0_1, x0_2, x0_3, Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x1_3)]), 64)\n\n    output = Conv2D(1, (1, 1), activation='sigmoid')(x0_4)\n\n    model = Model(inputs=[base_input, threshold_input], outputs=output)\n\n    return model\n\n# Example usage\ninput_shape = (224, 224, 1)\nmodel = unet_plus_plus(input_shape)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:41:41.892367Z","iopub.execute_input":"2024-08-03T15:41:41.892721Z","iopub.status.idle":"2024-08-03T15:41:45.623419Z","shell.execute_reply.started":"2024-08-03T15:41:41.892658Z","shell.execute_reply":"2024-08-03T15:41:45.622345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\n# Plot the model architecture\nplot_model(model, to_file='unet_model.png', show_shapes=True)\n\nfrom IPython.display import Image\n\n# Assuming the 'unet_model.png' file is in the current directory\nImage(filename='unet_model.png')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Compile (Needed)**","metadata":{"_uuid":"06d702f1b3957412bb2025c1b4fb3b2a322735d7"}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nimport tensorflow.keras.backend as K\nfrom sklearn.metrics import roc_auc_score\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef jaccard_index(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    sum_ = K.sum(y_true_f + y_pred_f)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef jaccard_loss(y_true, y_pred):\n    return 1 - jaccard_index(y_true, y_pred)\n\ndef auc(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    \n    def true_positive_rate(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        return true_positives / (possible_positives + K.epsilon())\n\n    def false_positive_rate(y_true, y_pred):\n        false_positives = K.sum(K.round(K.clip(y_pred * (1 - y_true), 0, 1)))\n        possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n        return false_positives / (possible_negatives + K.epsilon())\n\n    thresholds = [i * 0.1 for i in range(11)]\n    tprs = [true_positive_rate(y_true, K.cast(y_pred >= threshold, 'float32')) for threshold in thresholds]\n    fprs = [false_positive_rate(y_true, K.cast(y_pred >= threshold, 'float32')) for threshold in thresholds]\n    \n    tprs = K.stack(tprs)\n    fprs = K.stack(fprs)\n\n    auc_value = K.abs(K.sum((fprs[1:] - fprs[:-1]) * (tprs[1:] + tprs[:-1])) / 2)\n    \n    return auc_value\n\n\n\n\nmodel.compile(optimizer=Adam(lr=0.0001), loss=dice_coef_loss,\n                  metrics=[dice_coef, jaccard_index, auc, 'binary_accuracy'])\n\n\nprint('Compiled')","metadata":{"_uuid":"37e9815e1fbb5ff29d7ffab156541df200e94e2b","execution":{"iopub.status.busy":"2024-08-03T15:41:48.710243Z","iopub.execute_input":"2024-08-03T15:41:48.710596Z","iopub.status.idle":"2024-08-03T15:41:49.961991Z","shell.execute_reply.started":"2024-08-03T15:41:48.710519Z","shell.execute_reply":"2024-08-03T15:41:49.960882Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Fit (Needed)**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\n# Define ReduceLROnPlateau callback\nreduce_lr = ReduceLROnPlateau(monitor='val_dice_coef', \n                              factor=0.2, \n                              patience=15, \n                              verbose=1, \n                              mode='max',\n                              min_lr=1e-7)\n\nearly_stopping = EarlyStopping(\n    monitor='val_dice_coef', \n    patience=50, \n    verbose=1,\n    mode='max',\n)\n\ncheckpoint = ModelCheckpoint(\n    'best_weights', \n    monitor='val_dice_coef', \n    verbose=1, \n    save_best_only=True, \n    mode='max',\n)\n    \n    \n# Train the model\n# history = model.fit(train_generator, validation_data=val_generator, epochs=400, callbacks=[reduce_lr, early_stopping, checkpoint])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:42:13.872556Z","iopub.execute_input":"2024-08-03T15:42:13.872894Z","iopub.status.idle":"2024-08-03T15:42:13.882034Z","shell.execute_reply.started":"2024-08-03T15:42:13.872832Z","shell.execute_reply":"2024-08-03T15:42:13.881261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image, ImageEnhance\nfrom tensorflow.keras.utils import Sequence\nfrom sklearn.model_selection import KFold, train_test_split\nimport random\nimport matplotlib.pyplot as plt\nimport pickle\n\nclass DataGenerator(Sequence):\n    def __init__(self, original_filenames, threshold_filenames, mask_filenames, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=32, target_size=(224, 224), augment=False):\n        self.original_filenames = original_filenames\n        self.threshold_filenames = threshold_filenames\n        self.mask_filenames = mask_filenames\n        self.original_image_folder = original_image_folder\n        self.threshold_image_folder = threshold_image_folder\n        self.mask_image_folder = mask_image_folder\n        self.batch_size = batch_size\n        self.target_size = target_size\n        self.augment = augment\n\n    def __len__(self):\n        return int(np.ceil(len(self.original_filenames) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_original_filenames = self.original_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_threshold_filenames = self.threshold_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_mask_filenames = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        original_images = np.zeros((self.batch_size, *self.target_size, 1))\n        threshold_images = np.zeros((self.batch_size, *self.target_size, 1))\n        mask_images = np.zeros((self.batch_size, *self.target_size, 1))\n\n        for i, filename in enumerate(batch_original_filenames):\n            original_path = os.path.join(self.original_image_folder, filename)\n            threshold_path = os.path.join(self.threshold_image_folder, batch_threshold_filenames[i])\n            mask_path = os.path.join(self.mask_image_folder, batch_mask_filenames[i])\n\n            original_img = Image.open(original_path).convert('L').resize(self.target_size, Image.LANCZOS)\n            threshold_img = Image.open(threshold_path).convert('L').resize(self.target_size, Image.LANCZOS)\n            mask_img = Image.open(mask_path).convert('L').resize(self.target_size, Image.LANCZOS)\n\n            if self.augment:\n                original_img, threshold_img, mask_img = self.apply_augmentation(original_img, threshold_img, mask_img)\n\n            original_img = np.array(original_img) / 255.0\n            threshold_img = np.array(threshold_img) / 255.0\n            mask_img = np.array(mask_img) / 255.0\n\n            original_images[i, :, :, 0] = original_img\n            threshold_images[i, :, :, 0] = threshold_img\n            mask_images[i, :, :, 0] = mask_img\n\n        return [original_images, threshold_images], mask_images\n\n    def apply_augmentation(self, original_img, threshold_img, mask_img):\n        # Random rotation\n        if random.random() > 0.5:\n            angle = random.uniform(-10, 10)\n            original_img = original_img.rotate(angle)\n            threshold_img = threshold_img.rotate(angle)\n            mask_img = mask_img.rotate(angle)\n\n        # Random zoom\n        if random.random() > 0.5:\n            scale = random.uniform(0.8, 1.2)\n            w, h = original_img.size\n            new_w, new_h = int(w * scale), int(h * scale)\n            original_img = original_img.resize((new_w, new_h), Image.LANCZOS)\n            threshold_img = threshold_img.resize((new_w, new_h), Image.LANCZOS)\n            mask_img = mask_img.resize((new_w, new_h), Image.LANCZOS)\n\n            # Center crop to original size\n            left = (new_w - w) // 2\n            top = (new_h - h) // 2\n            original_img = original_img.crop((left, top, left + w, top + h))\n            threshold_img = threshold_img.crop((left, top, left + w, top + h))\n            mask_img = mask_img.crop((left, top, left + w, top + h))\n\n        # Random crop\n#         if random.random() > 0.5:\n#             crop_size = random.uniform(0.8, 1.0)\n#             w, h = original_img.size\n#             new_w, new_h = int(w * crop_size), int(h * crop_size)\n#             left = random.randint(0, w - new_w)\n#             top = random.randint(0, h - new_h)\n#             original_img = original_img.crop((left, top, left + new_w, top + new_h))\n#             threshold_img = threshold_img.crop((left, top, left + new_w, top + new_h))\n#             mask_img = mask_img.crop((left, top, left + new_w, top + new_h))\n\n#             # Resize back to original size\n#             original_img = original_img.resize((w, h), Image.LANCZOS)\n#             threshold_img = threshold_img.resize((w, h), Image.LANCZOS)\n#             mask_img = mask_img.resize((w, h), Image.LANCZOS)\n\n        # Random brightness adjustment\n#         if random.random() > 0.5:\n#             enhancer = ImageEnhance.Brightness(original_img)\n#             original_img = enhancer.enhance(random.uniform(0.8, 1.2))\n#             enhancer = ImageEnhance.Brightness(threshold_img)\n#             threshold_img = enhancer.enhance(random.uniform(0.8, 1.2))\n\n        # Random contrast adjustment\n#         if random.random() > 0.5:\n#             enhancer = ImageEnhance.Contrast(original_img)\n#             original_img = enhancer.enhance(random.uniform(0.8, 1.2))\n#             enhancer = ImageEnhance.Contrast(threshold_img)\n#             threshold_img = enhancer.enhance(random.uniform(0.8, 1.2))\n\n        return original_img, threshold_img, mask_img\n\n# Paths to the datasets\noriginal_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/cxr'\nthreshold_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/threshold'\nmask_image_folder = '/kaggle/input/segdata/SegData/jsrtshenmonenh/masks'\n\n# Get the list of filenames\noriginal_filenames = sorted(os.listdir(original_image_folder))\nthreshold_filenames = sorted(os.listdir(threshold_image_folder))\nmask_filenames = sorted(os.listdir(mask_image_folder))\n\n# Split the data into training/validation (80%) and test (20%) sets\ntrain_val_original, test_original, train_val_threshold, test_threshold, train_val_mask, test_mask = train_test_split(\n    original_filenames, threshold_filenames, mask_filenames, test_size=0.2, random_state=42)\n\n# Create the test DataGenerator instance\ntest_generator = DataGenerator(test_original, test_threshold, test_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n\n\nhistory_data=[]\n\n# Initialize KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Perform cross-validation\nfold = 0\nfor train_index, val_index in kf.split(train_val_original):\n    fold += 1\n    print(f\"### Training fold {fold}\")\n\n    # Split data into training and validation sets\n    train_original = [train_val_original[i] for i in train_index]\n    val_original = [train_val_original[i] for i in val_index]\n    train_threshold = [train_val_threshold[i] for i in train_index]\n    val_threshold = [train_val_threshold[i] for i in val_index]\n    train_mask = [train_val_mask[i] for i in train_index]\n    val_mask = [train_val_mask[i] for i in val_index]\n\n    # Create DataGenerator instances\n    train_generator = DataGenerator(train_original, train_threshold, train_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16, augment=True)\n    val_generator = DataGenerator(val_original, val_threshold, val_mask, original_image_folder, threshold_image_folder, mask_image_folder, batch_size=16)\n\n    # Define your callbacks here\n    callbacks = [reduce_lr, early_stopping, checkpoint]\n\n    # Train the model\n    history = model.fit(train_generator, validation_data=val_generator, epochs=100, callbacks=callbacks)\n\n    history_data.append(history)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:42:16.645537Z","iopub.execute_input":"2024-08-03T15:42:16.645809Z","iopub.status.idle":"2024-08-03T18:24:15.947032Z","shell.execute_reply.started":"2024-08-03T15:42:16.645769Z","shell.execute_reply":"2024-08-03T18:24:15.945869Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_weights('/kaggle/working/final_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:25:59.973965Z","iopub.execute_input":"2024-08-03T18:25:59.974272Z","iopub.status.idle":"2024-08-03T18:26:00.219781Z","shell.execute_reply.started":"2024-08-03T18:25:59.974224Z","shell.execute_reply":"2024-08-03T18:26:00.218981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Evaluate the model on the test set\n# test_loss, test_accuracy = model.evaluate(test_generator)\n# print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# # Plot training & validation loss values\n# plt.figure(figsize=(12, 6))\n\n# plt.subplot(1, 2, 1)\n# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('Model loss')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Validation'], loc='upper right')\n\n# # Plot training & validation Dice coefficient values\n# plt.subplot(1, 2, 2)\n# plt.plot(history.history['dice_coef'])\n# plt.plot(history.history['val_dice_coef'])\n# plt.title('Model Dice Coefficient')\n# plt.ylabel('Dice Coefficient')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Validation'], loc='lower right')\n\n# plt.tight_layout()\n# plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tr_acc=[]\ntr_loss=[]\nval_acc=[]\nval_loss=[]\nfor history in history_data:\n  n=len(history.history['dice_coef'])\n  for i in range(n):\n    tr_acc.append(history.history['dice_coef'][i])\n    tr_loss.append(history.history['loss'][i])\n    val_acc.append(history.history['val_dice_coef'][i])\n    val_loss.append(history.history['val_loss'][i])\n\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Dice Co-ef')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Dice Co-ef')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Dice Co-ef')\nplt.xlabel('Epochs')\nplt.ylabel('Dice Co-ef')\nplt.legend()\n\nplt.tight_layout\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:04.383944Z","iopub.execute_input":"2024-08-03T18:26:04.384244Z","iopub.status.idle":"2024-08-03T18:26:05.182222Z","shell.execute_reply.started":"2024-08-03T18:26:04.384197Z","shell.execute_reply":"2024-08-03T18:26:05.181281Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Validation (Needed)**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Evaluate the model on the validation data\nresults = model.evaluate(test_generator)\nloss = results[0]\naccuracy = results[1]\ndice = results[2]\nprint(f\"Test loss: {loss:.4f}\")\nprint(f\"Test dice: {accuracy:.4f}\")\nprint(f\"Test binary accuracy: {dice:.4f}\")\nprint(results)\n\n# Number of predictions to plot\nn = 10\n\n# Plot predictions\nfor i in range(n):\n    # Get a batch of images from the validation generator\n    X_batch, Y_batch = next(iter(val_generator))\n\n    # Extract images from the batch\n    blurred_images = X_batch[0]\n    threshold_images = X_batch[1]\n    original_images = Y_batch\n\n    blurred_image = blurred_images[i]\n    threshold_image = threshold_images[i]\n    original_image = original_images[i]\n\n    # Predict the original image from the blurred image and threshold image\n    predicted_image = model.predict([np.expand_dims(blurred_image, axis=0),\n                                     np.expand_dims(threshold_image, axis=0)])[0]\n\n    # Plot the images\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 4, 1)\n    plt.imshow(blurred_image.squeeze(), cmap='gray')\n    plt.title(\"Blurred Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 2)\n    plt.imshow(threshold_image.squeeze(), cmap='gray')\n    plt.title(\"Threshold Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 3)\n    plt.imshow(original_image.squeeze(), cmap='gray')\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 4)\n    plt.imshow(predicted_image.squeeze(), cmap='gray')\n    plt.title(\"Predicted Image\")\n    plt.axis('off')\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:20.821353Z","iopub.execute_input":"2024-08-03T18:26:20.82175Z","iopub.status.idle":"2024-08-03T18:26:31.548997Z","shell.execute_reply.started":"2024-08-03T18:26:20.821683Z","shell.execute_reply":"2024-08-03T18:26:31.54823Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_weights('/kaggle/working/best_weights')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:37.087701Z","iopub.execute_input":"2024-08-03T18:26:37.088023Z","iopub.status.idle":"2024-08-03T18:26:37.91239Z","shell.execute_reply.started":"2024-08-03T18:26:37.087973Z","shell.execute_reply":"2024-08-03T18:26:37.911744Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Evaluate the model on the validation data\nresults = model.evaluate(test_generator)\nloss = results[0]\naccuracy = results[1]\ndice = results[2]\nprint(f\"Test loss: {loss:.4f}\")\nprint(f\"Test dice: {accuracy:.4f}\")\nprint(f\"Test binary accuracy: {dice:.4f}\")\nprint(results)\n\n# Number of predictions to plot\nn = 10\n\n# Plot predictions\nfor i in range(n):\n    # Get a batch of images from the validation generator\n    X_batch, Y_batch = next(iter(val_generator))\n\n    # Extract images from the batch\n    blurred_images = X_batch[0]\n    threshold_images = X_batch[1]\n    original_images = Y_batch\n\n    blurred_image = blurred_images[i]\n    threshold_image = threshold_images[i]\n    original_image = original_images[i]\n\n    # Predict the original image from the blurred image and threshold image\n    predicted_image = model.predict([np.expand_dims(blurred_image, axis=0),\n                                     np.expand_dims(threshold_image, axis=0)])[0]\n\n    # Plot the images\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 4, 1)\n    plt.imshow(blurred_image.squeeze(), cmap='gray')\n    plt.title(\"Blurred Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 2)\n    plt.imshow(threshold_image.squeeze(), cmap='gray')\n    plt.title(\"Threshold Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 3)\n    plt.imshow(original_image.squeeze(), cmap='gray')\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 4)\n    plt.imshow(predicted_image.squeeze(), cmap='gray')\n    plt.title(\"Predicted Image\")\n    plt.axis('off')\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:40.449256Z","iopub.execute_input":"2024-08-03T18:26:40.44965Z","iopub.status.idle":"2024-08-03T18:26:48.231362Z","shell.execute_reply.started":"2024-08-03T18:26:40.449586Z","shell.execute_reply":"2024-08-03T18:26:48.230401Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\n\n# Define the Dice coefficient function\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# Evaluate the model on the test data\nresults = model.evaluate(test_generator)\nloss = results[0]\naccuracy = results[1]\nprint(f\"Test loss: {loss:.4f}\")\nprint(f\"Test accuracy: {accuracy:.4f}\")\n\n# Calculate Dice coefficient for the test set\ndice_scores = []\n\nfor i in range(len(test_generator)):\n    # Get a batch of images from the test generator\n    X_batch, Y_batch = test_generator[i]\n\n    # Extract images from the batch\n    blurred_images = X_batch[0]\n    threshold_images = X_batch[1]\n    original_images = Y_batch\n\n    # Predict the original image from the blurred image and threshold image\n    predicted_images = model.predict([blurred_images, threshold_images])\n\n    # Calculate Dice coefficient for each image in the batch\n    for j in range(len(predicted_images)):\n        dice_score = dice_coef(original_images[j], predicted_images[j])\n        dice_scores.append(dice_score)\n\n# Calculate the average Dice coefficient\naverage_dice_score = np.mean(dice_scores)\nprint(f\"Average Dice coefficient: {average_dice_score:.4f}\")\n\n# Plot predictions and Dice coefficient for a few examples\nn = 10  # Number of predictions to plot\n\nfor i in range(n):\n    # Get a batch of images from the test generator\n    X_batch, Y_batch = next(iter(test_generator))\n\n    # Extract images from the batch\n    blurred_images = X_batch[0]\n    threshold_images = X_batch[1]\n    original_images = Y_batch\n\n    blurred_image = blurred_images[i]\n    threshold_image = threshold_images[i]\n    original_image = original_images[i]\n\n    # Predict the original image from the blurred image and threshold image\n    predicted_image = model.predict([np.expand_dims(blurred_image, axis=0),\n                                     np.expand_dims(threshold_image, axis=0)])[0]\n\n    # Calculate the Dice coefficient for the current image\n    dice_score = dice_coef(original_image, predicted_image)\n    \n    # Plot the images and Dice coefficient\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 4, 1)\n    plt.imshow(blurred_image.squeeze(), cmap='gray')\n    plt.title(\"Blurred Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 2)\n    plt.imshow(threshold_image.squeeze(), cmap='gray')\n    plt.title(\"Threshold Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 3)\n    plt.imshow(original_image.squeeze(), cmap='gray')\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 4)\n    plt.imshow(predicted_image.squeeze(), cmap='gray')\n    plt.title(f\"Predicted Image\\nDice: {K.eval(dice_score):.4f}\")\n    plt.axis('off')\n\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n\n# Define the Dice coefficient function\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.cast(K.flatten(y_true), 'float32')\n    y_pred_f = K.cast(K.flatten(y_pred), 'float32')\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# Evaluate the model on the test data\nresults = model.evaluate(test_generator)\nloss = results[0]\naccuracy = results[1]\nprint(f\"Test loss: {loss:.4f}\")\nprint(f\"Test accuracy: {accuracy:.4f}\")\n\n# Calculate Dice coefficient for the test set\ndice_scores = []\n\nfor i in range(len(test_generator)):\n    # Get a batch of images from the test generator\n    X_batch, Y_batch = test_generator[i]\n\n    # Extract images from the batch\n    blurred_images = X_batch[0]\n    threshold_images = X_batch[1]\n    original_images = Y_batch\n\n    # Predict the original image from the blurred image and threshold image\n    predicted_images = model.predict([blurred_images, threshold_images])\n\n    # Calculate Dice coefficient for each image in the batch\n    for j in range(len(predicted_images)):\n        dice_score = dice_coef(original_images[j], predicted_images[j])\n        dice_scores.append(K.eval(dice_score))\n\n# Calculate the average Dice coefficient\naverage_dice_score = np.mean(dice_scores)\nprint(f\"Average Dice coefficient: {average_dice_score:.4f}\")\n\n# Plot predictions and Dice coefficient for a few examples\nn = 10  # Number of predictions to plot\n\nfor i in range(n):\n    # Get a batch of images from the test generator\n    X_batch, Y_batch = next(iter(test_generator))\n\n    # Extract images from the batch\n    blurred_images = X_batch[0]\n    threshold_images = X_batch[1]\n    original_images = Y_batch\n\n    blurred_image = blurred_images[i]\n    threshold_image = threshold_images[i]\n    original_image = original_images[i]\n\n    # Predict the original image from the blurred image and threshold image\n    predicted_image = model.predict([np.expand_dims(blurred_image, axis=0),\n                                     np.expand_dims(threshold_image, axis=0)])[0]\n\n    # Calculate the Dice coefficient for the current image\n    dice_score = dice_coef(original_image, predicted_image)\n    \n    # Plot the images and Dice coefficient\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 4, 1)\n    plt.imshow(blurred_image.squeeze(), cmap='gray')\n    plt.title(\"Blurred Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 2)\n    plt.imshow(threshold_image.squeeze(), cmap='gray')\n    plt.title(\"Threshold Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 3)\n    plt.imshow(original_image.squeeze(), cmap='gray')\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 4, 4)\n    plt.imshow(predicted_image.squeeze(), cmap='gray')\n    plt.title(f\"Predicted Image\\nDice: {K.eval(dice_score):.4f}\")\n    plt.axis('off')\n\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_weights('/kaggle/working/final_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:38:10.634037Z","iopub.execute_input":"2024-08-03T15:38:10.634357Z","iopub.status.idle":"2024-08-03T15:38:10.837936Z","shell.execute_reply.started":"2024-08-03T15:38:10.634292Z","shell.execute_reply":"2024-08-03T15:38:10.837026Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\n\n# Define file paths for the images\nimage_paths = [\n    '/kaggle/working/data4200/enhanced_images/Normal/Normal-100.png',\n    '/kaggle/working/data4200/threshold_images/Normal/Normal-100.png',\n    '/kaggle/working/data4200/threshold_images/Normal/Normal-1.png'\n]\n\n# Load the images and check their shapes\nimage_shapes = []\nfor path in image_paths:\n    img = Image.open(path)\n    img_array = np.array(img)\n    image_shapes.append(img_array.shape)\n\nprint(image_shapes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Prediction on 4200 (Needed)**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\nfrom PIL import Image\n\n# Define paths\ninput_folder = '/kaggle/working/shen/cxr'\nthreshold_folder = '/kaggle/working/shen/threshold'\noutput_folder = '/kaggle/working/shenmask/modelmask'\n# model_path = 'path_to_your_trained_unet_model.h5'\n\n# Ensure the output folder exists\nos.makedirs(output_folder, exist_ok=True)\n\n# Load the trained U-Net model\n# model = load_model(model_path)\n\n# Get the list of files\ninput_files = sorted(os.listdir(input_folder))\nthreshold_files = sorted(os.listdir(threshold_folder))\n\n# Ensure the files in both folders match\nassert len(input_files) == len(threshold_files), \"The number of files in the input and threshold folders do not match.\"\n\n# Iterate over the files and process each one\nfor input_file, threshold_file in zip(input_files, threshold_files):\n    # Load and preprocess the input image\n    input_image_path = os.path.join(input_folder, input_file)\n    threshold_image_path = os.path.join(threshold_folder, threshold_file)\n    \n    input_image = load_img(input_image_path, color_mode='grayscale', target_size=(224, 224))\n    threshold_image = load_img(threshold_image_path, color_mode='grayscale', target_size=(224, 224))\n    \n    input_image_array = img_to_array(input_image) / 255.0\n    threshold_image_array = img_to_array(threshold_image) / 255.0\n    \n    input_image_array = np.expand_dims(input_image_array, axis=0)\n    threshold_image_array = np.expand_dims(threshold_image_array, axis=0)\n    \n    # Predict the output\n    prediction = model.predict([input_image_array, threshold_image_array])\n    \n    # Post-process and save the output image\n    prediction_image = prediction[0, :, :, 0] * 255.0\n    prediction_image = prediction_image.astype(np.uint8)\n    prediction_image = Image.fromarray(prediction_image)\n    \n    output_image_path = os.path.join(output_folder, input_file)\n    prediction_image.save(output_image_path)\n\nprint(\"Predictions saved to\", output_folder)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\n# Define a function to convert an image to a threshold image\ndef convert_to_threshold(image, threshold_value=128):\n    image_array = img_to_array(image)\n    threshold_image_array = (image_array > threshold_value).astype(np.uint8) * 255\n    return Image.fromarray(threshold_image_array.squeeze(), 'L')\n\n\n# Load and preprocess the input image\ninput_image_path = '/kaggle/working/tb4200/cxr/Tuberculosis-107.png'\nthreshold_image_path = '/kaggle/working/tb4200/threshold/Tuberculosis-107.png'\n\ninput_image = load_img(input_image_path, color_mode='grayscale', target_size=(224, 224))\nthreshold_image = load_img(threshold_image_path, color_mode='grayscale', target_size=(224, 224))\n\ninput_image_array = img_to_array(input_image) / 255.0\nthreshold_image_array = img_to_array(threshold_image) / 255.0\n\ninput_image_array = np.expand_dims(input_image_array, axis=0)\nthreshold_image_array = np.expand_dims(threshold_image_array, axis=0)\n\n# # Manually convert the input image to a threshold image\n# threshold_image = convert_to_threshold(input_image, threshold_value=128)\n# threshold_image_array = img_to_array(threshold_image) / 255.0\n# threshold_image_array = np.expand_dims(threshold_image_array, axis=0)\n\n# Predict the output\nprediction = model.predict([input_image_array, threshold_image_array])\n\n# Post-process and save the output image\nprediction_image = prediction[0, :, :, 0] * 255.0\nprediction_image = prediction_image.astype(np.uint8)\nprediction_image = Image.fromarray(prediction_image)\n\n\n# Plot the images and Dice coefficient\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.imshow(input_image, cmap='gray')\nplt.title(\"Blurred Image\")\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(threshold_image, cmap='gray')\nplt.title(\"Threshold Image\")\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(prediction_image, cmap='gray')\nplt.title(\"Original Image\")\nplt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:38:35.629675Z","iopub.execute_input":"2024-08-03T15:38:35.629997Z","iopub.status.idle":"2024-08-03T15:38:36.040128Z","shell.execute_reply.started":"2024-08-03T15:38:35.629952Z","shell.execute_reply":"2024-08-03T15:38:36.039345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom PIL import Image\n\ndef list_files(folder):\n    \"\"\"Returns a set of file names in the given folder.\"\"\"\n    return set(os.listdir(folder))\n\ndef find_missing_files(folder1, folder2):\n    \"\"\"Finds files in folder1 that are not present in folder2.\"\"\"\n    files1 = list_files(folder1)\n    files2 = list_files(folder2)\n    missing_files = files1 - files2\n    return missing_files\n\n# Define paths\ninput_folder = '/kaggle/working/shenmon/cxr'\nthreshold_folder = '/kaggle/working/shenmon/threshold'\noutput_folder = '/kaggle/working/predmasks'\nmodel_path = '/kaggle/input/latestunet/unet_model_weights.h5'\n\n# Ensure the output folder exists\nos.makedirs(output_folder, exist_ok=True)\n\n# Load the trained U-Net model\nmodel.load_weights(model_path)\n\n# Get the list of files\ninput_files = sorted(os.listdir(input_folder))\nthreshold_files = sorted(os.listdir(threshold_folder))\n\n# Ensure the files in both folders match\nassert len(input_files) == len(threshold_files), \"The number of files in the input and threshold folders do not match.\"\n\n\n# Iterate over the files and process each one if it's in the missing_files set\nfor input_file, threshold_file in zip(input_files, threshold_files):\n    if input_file in missing_files:\n        # Load and preprocess the input image\n        input_image_path = os.path.join(input_folder, input_file)\n        threshold_image_path = os.path.join(threshold_folder, threshold_file)\n        \n        input_image = load_img(input_image_path, color_mode='grayscale', target_size=(224, 224))\n        threshold_image = load_img(threshold_image_path, color_mode='grayscale', target_size=(224, 224))\n        \n        input_image_array = img_to_array(input_image) / 255.0\n        threshold_image_array = img_to_array(threshold_image) / 255.0\n        \n        input_image_array = np.expand_dims(input_image_array, axis=0)\n        threshold_image_array = np.expand_dims(threshold_image_array, axis=0)\n        \n        # Predict the output\n        prediction = model.predict([input_image_array, threshold_image_array])\n        \n        # Post-process and save the output image\n        prediction_image = prediction[0, :, :, 0] * 255.0\n        prediction_image = prediction_image.astype(np.uint8)\n        prediction_image = Image.fromarray(prediction_image)\n        \n        output_image_path = os.path.join(output_folder, input_file)\n        prediction_image.save(output_image_path)\n\nprint(\"Predictions saved to\", output_folder)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\n# Replace 'path/to/image.png' with the actual path where you downloaded the image\nimage = plt.imread('/kaggle/working/data4200/enhanced_images/Tuberculosis/Tuberculosis-342.png')\nplt.imshow(image)\nplt.show()\n\n# Replace 'path/to/image.png' with the actual path where you downloaded the image\nimage = plt.imread('/kaggle/working/data4200/threshold_images/Tuberculosis/Tuberculosis-342.png')\nplt.imshow(image)\nplt.show()\n\n\n# Replace 'path/to/image.png' with the actual path where you downloaded the image\nimage = plt.imread('/kaggle/working/data4200/masks/Tuberculosis/Tuberculosis-342.png')\nplt.imshow(image)\nprint(image.shape)\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef plot_images_in_folder(folder_path):\n    # Get list of files in the folder\n    files = sorted(os.listdir(folder_path))\n    \n    # Filter files to keep only image files\n    image_files = [f for f in files if f.lower().endswith(('png', 'jpg', 'jpeg', 'gif', 'bmp'))][50:150]\n    \n    # Set up matplotlib figure\n    num_images = len(image_files)\n    num_cols = 4\n    num_rows = (num_images + num_cols - 1) // num_cols\n    \n    plt.figure(figsize=(15, 5 * num_rows))\n    \n    for i, file in enumerate(image_files):\n        image_path = os.path.join(folder_path, file)\n        \n        # Load image using PIL\n        image = Image.open(image_path)\n        \n        # Plot image\n        plt.subplot(num_rows, num_cols, i + 1)\n        plt.imshow(image)\n        plt.title(file)\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nfolder_path = '/kaggle/working/data4200/masks/Tuberculosis'  # Replace with your folder path\nplot_images_in_folder(folder_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef plot_images_in_folder(folder_path):\n    # Get list of files in the folder\n    files = sorted(os.listdir(folder_path))\n    \n    # Filter files to keep only image files\n    image_files = [f for f in files if f.lower().endswith(('png', 'jpg', 'jpeg', 'gif', 'bmp'))][50:150]\n    \n    # Set up matplotlib figure\n    num_images = len(image_files)\n    num_cols = 4\n    num_rows = (num_images + num_cols - 1) // num_cols\n    \n    plt.figure(figsize=(15, 5 * num_rows))\n    \n    for i, file in enumerate(image_files):\n        image_path = os.path.join(folder_path, file)\n        \n        # Load image using PIL\n        image = Image.open(image_path)\n        \n        # Plot image\n        plt.subplot(num_rows, num_cols, i + 1)\n        plt.imshow(image)\n        plt.title(file)\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nfolder_path = '/kaggle/working/data4200/masks/Normal'  # Replace with your folder path\nplot_images_in_folder(folder_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# import os\n# import numpy as np\n# from tensorflow.keras.models import load_model\n# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n# from PIL import Image\n# import matplotlib.pyplot as plt\n\n# # Choose a single image from the folder\n# input_file = 'Tuberculosis-342.png'\n\n# # Load and preprocess the input image\n# input_image_path = os.path.join(input_folder, input_file)\n\n# # Load the original image\n# input_image = load_img(input_image_path, color_mode='grayscale', target_size=(224, 224))\n\n# # Define preprocessing options for the original image\n# def preprocess_image(image):\n#     image_array = img_to_array(image) / 255.0\n#     image_array = np.expand_dims(image_array, axis=0)\n#     return image_array\n\n# input_image_array = preprocess_image(input_image)\n\n# # Generate the threshold image\n# threshold_image_array = np.zeros_like(input_image_array)  # Initialize with zeros\n# threshold_image_array[input_image_array >= 0.2] = 0.7  # Example thresholding condition\n\n\n# # Predict the output (uncomment once you have loaded your model)\n# # prediction = model.predict([input_image_array, np.expand_dims(threshold_image_array, axis=0)])\n\n# # Predict the output (uncomment once you have loaded your model)\n# prediction = model.predict([input_image_array, threshold_image_array])\n\n\n# # Post-process the output image\n# # Post-process and save the output image\n# prediction_image = prediction[0, :, :, 0] * 255.0\n# prediction_image = prediction_image.astype(np.uint8)\n# prediction_image = Image.fromarray(prediction_image)\n\n# # Plot the original, threshold, and predicted images\n# plt.figure(figsize=(12, 4))\n\n# # Original image\n# plt.subplot(1, 3, 1)\n# plt.imshow(input_image_array[0, :, :, 0], cmap='gray')\n# plt.title('Original Image')\n# plt.axis('off')\n\n# # Threshold image\n# plt.subplot(1, 3, 2)\n# plt.imshow(threshold_image_array[0, :, :, 0], cmap='gray')\n# plt.title('Threshold Image')\n# plt.axis('off')\n\n# # Predicted image\n# plt.subplot(1, 3, 3)\n# plt.imshow(prediction_image, cmap='gray')\n# plt.title('Predicted Mask')\n# plt.axis('off')\n\n# plt.tight_layout()\n# plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# # Define the path to the file to be deleted\n# file_path = '/kaggle/working/data4200/masks/Tuberculosis/predicted_mask.png'\n\n# # Check if the file exists before attempting to delete\n# if os.path.exists(file_path):\n#     os.remove(file_path)\n#     print(f\"File {file_path} has been deleted.\")\n# else:\n#     print(f\"File {file_path} does not exist.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Callbacks, Early Stopping and Reduced LR\n","metadata":{"_uuid":"9884bf48369bf28f4b0fcb9eb1a1fa4cc4bdd17c"}},{"cell_type":"code","source":"model.load_weights('/kaggle/input/cxr-mask-weight-high/cxr_reg_weights.best_high.hdf5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the image and output directory\nimage_path = '/kaggle/input/tb-images-enhanced/content/enhanced_images/Tuberculosis-510.png'\noutput_dir = '/kaggle/working/Try'\n\n# Ensure output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Function to load and preprocess image\ndef load_and_preprocess_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (512, 512))\n    img = img / 255.0\n    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n    return img\n\n# Function to predict mask and save it\ndef predict_and_save_mask(image_path, output_dir, model):\n    image = load_and_preprocess_image(image_path)\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    mask = model.predict(image)[0]\n    mask = (mask * 255).astype(np.uint8)\n\n    # Save the mask image\n    filename = os.path.basename(image_path)\n    mask_output_path = os.path.join(output_dir, f'{os.path.splitext(filename)[0]}_mask.png')\n    cv2.imwrite(mask_output_path, mask)\n\n# Create mask for the specified image\npredict_and_save_mask(image_path, output_dir, model)\n\nprint(\"Mask generation complete.\")\n\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Load the image\nimage_path = '/kaggle/working/Try/Tuberculosis-510_mask.png'  # Replace with your image path\nimage = Image.open(image_path)\n\n# Plot the image\nplt.imshow(image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Load the image\nimage_path = '/kaggle/working/Try/Tuberculosis-1_mask.png'  # Replace with your image path\nimage = Image.open(image_path)\n\n# Plot the image\nplt.imshow(image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Path to the input directory and output directory\ninput_dir = '/kaggle/working//TB_Norm_Enhanced'\noutput_dir = '/kaggle/working/Mask_Norm/'\n\n# Ensure output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Function to load and preprocess image\ndef load_and_preprocess_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (512, 512))\n    img = img / 255.0\n    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n    return img\n\n# Function to predict mask and save it\ndef predict_and_save_mask(image_path, output_dir, model):\n    image = load_and_preprocess_image(image_path)\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    mask = model.predict(image)[0]\n    mask = (mask * 255).astype(np.uint8)\n\n    # Save the mask image\n    filename = os.path.basename(image_path)\n    mask_output_path = os.path.join(output_dir, f'{os.path.splitext(filename)[0]}.png')\n    cv2.imwrite(mask_output_path, mask)\n\n# Iterate through all images in the input directory\nfor filename in os.listdir(input_dir):\n    if filename.endswith('.png') or filename.endswith('.jpg'):\n        image_path = os.path.join(input_dir, filename)\n        predict_and_save_mask(image_path, output_dir, model)\n\nprint(\"Mask generation complete for all images.\")\n\n# Plot an example image\nexample_image_path = os.path.join(output_dir, 'Normal-500.png')  # Replace with an actual mask image path\nimage = Image.open(example_image_path)\n\n# Plot the image\nplt.imshow(image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Specify the folder you want to zip\nfolder_to_zip = '/kaggle/working/TB_Norm_Enhanced'\n\n# Specify the name and path for the output zip file\noutput_zip_file = '/kaggle/working/TB_Norm_Enhanced.zip'\n\n# Create the zip archive\nshutil.make_archive(base_name=output_zip_file.replace('.zip', ''), format='zip', root_dir=folder_to_zip)\n\nprint(f\"Folder '{folder_to_zip}' has been zipped as '{output_zip_file}'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import imageio\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport matplotlib.pyplot as plt\n\n# Step 1: Read the mask image\nmask_image_path = '/kaggle/working/Try/Tuberculosis-500_mask.png'\nmask_image = imageio.imread(mask_image_path)\n\n# Step 2: Convert to binary array (if not already binary)\nbinary_mask = mask_image > 0  # Adjust the threshold as needed\n\n# Step 3: Fill holes in the binary mask\nfilled_mask = binary_fill_holes(binary_mask)\n\n# Step 4: Save or display the filled mask\noutput_image_path = '/kaggle/working/Try/filled_mask.png'\nimageio.imwrite(output_image_path, (filled_mask * 255).astype(np.uint8))\n\n# Optional: Display the original and filled mask\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.title('Original Mask')\nplt.imshow(mask_image, cmap='gray')\n\nplt.subplot(1, 2, 2)\nplt.title('Filled Mask')\nplt.imshow(filled_mask, cmap='gray')\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import imageio\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes, binary_dilation\nimport matplotlib.pyplot as plt\n\n# Step 1: Read the mask image\nmask_image_path = '/kaggle/working/data4200/masks/Tuberculosis/Tuberculosis-1.png'\nmask_image = imageio.imread(mask_image_path)\n\n# Step 2: Convert to binary array (if not already binary)\nbinary_mask = mask_image > 150  # Adjust the threshold as needed\n\n# Step 3: Fill holes in the binary mask\nfilled_mask = binary_fill_holes(binary_mask)\n\n# Step 4: Apply binary dilation\ndilated_mask = binary_dilation(filled_mask, iterations=10)\n\n# Fill holes again after dilation\nagain_filled_mask = binary_fill_holes(dilated_mask)\n\n# Step 5: Save the processed mask\noutput_image_path = '/kaggle/working/processed_mask.png'\nimageio.imwrite(output_image_path, (again_filled_mask * 255).astype(np.uint8))\n\n# Display the original, filled, dilated, and again filled masks\nplt.figure(figsize=(20, 5))\n\nplt.subplot(1, 4, 1)\nplt.title('Original Mask')\nplt.imshow(mask_image, cmap='gray')\n\nplt.subplot(1, 4, 2)\nplt.title('Filled Mask')\nplt.imshow(filled_mask, cmap='gray')\n\nplt.subplot(1, 4, 3)\nplt.title('Dilated Mask')\nplt.imshow(dilated_mask, cmap='gray')\n\nplt.subplot(1, 4, 4)\nplt.title('Again Filled Mask')\nplt.imshow(again_filled_mask, cmap='gray')\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Final Process (Needed)**","metadata":{}},{"cell_type":"code","source":"import imageio\nimport numpy as np\nimport os\nfrom scipy.ndimage import binary_fill_holes, binary_dilation\nimport matplotlib.pyplot as plt\n\n# Define the input and output directories\ninput_dir = '/kaggle/working/shenmask/modelmask'\noutput_dir = '/kaggle/working/shenmask/enh10'\n\n# Ensure the output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Process each image in the input directory\nfor filename in os.listdir(input_dir):\n    if filename.endswith('.png'):  # Adjust the extension if needed\n        # Step 1: Read the mask image\n        mask_image_path = os.path.join(input_dir, filename)\n        mask_image = imageio.imread(mask_image_path)\n\n        # Step 2: Convert to binary array (if not already binary)\n        binary_mask = mask_image > 150  # Adjust the threshold as needed\n\n        # Step 3: Fill holes in the binary mask\n        filled_mask = binary_fill_holes(binary_mask)\n\n        # Step 4: Apply binary dilation\n        dilated_mask = binary_dilation(filled_mask, iterations=10)\n\n        # Fill holes again after dilation\n        again_filled_mask = binary_fill_holes(dilated_mask)\n\n        # Step 5: Save the processed mask\n        output_image_path = os.path.join(output_dir, filename)\n        imageio.imwrite(output_image_path, (again_filled_mask * 255).astype(np.uint8))\n\n# Display the original, filled, dilated, and again filled masks for the last processed image\nplt.figure(figsize=(20, 5))\n\nplt.subplot(1, 4, 1)\nplt.title('Original Mask')\nplt.imshow(mask_image, cmap='gray')\n\nplt.subplot(1, 4, 2)\nplt.title('Filled Mask')\nplt.imshow(filled_mask, cmap='gray')\n\nplt.subplot(1, 4, 3)\nplt.title('Dilated Mask')\nplt.imshow(dilated_mask, cmap='gray')\n\nplt.subplot(1, 4, 4)\nplt.title('Again Filled Mask')\nplt.imshow(again_filled_mask, cmap='gray')\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\n\n# Define the input and output directories\ninput_dir = '/kaggle/working/shenmask/enh3'\noutput_dir = '/kaggle/working/shenmask/enh3dill20'\n\n# Create the output directory if it doesn't exist\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Create a vertical kernel for dilation\nkernel = np.array([[0, 1, 0],\n                   [0, 1, 0],\n                   [0, 0, 0]], dtype=np.uint8)\n\n# Iterate over all files in the input directory\nfor filename in os.listdir(input_dir):\n    if filename.endswith(\".png\"):  # Check if the file is a PNG image\n        # Construct the full path to the input image\n        image_path = os.path.join(input_dir, filename)\n        \n        # Read the binary mask image\n        binary_mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Apply dilation with 20 iterations\n        dilated_mask = cv2.dilate(binary_mask, kernel, iterations=20)\n        \n        # Construct the full path to the output image\n        output_path = os.path.join(output_dir, filename)\n        \n        # Save the dilated mask image\n        cv2.imwrite(output_path, dilated_mask)\n\nprint(\"Dilation applied to all images and saved to the output directory.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Specify the folder you want to zip\nfolder_to_zip = '/kaggle/working/montmaskdilldown'\n\n# Specify the name and path for the output zip file\noutput_zip_file = '/kaggle/working/montmaskdilldown.zip'\n\n# Create the zip archive\nshutil.make_archive(base_name=output_zip_file.replace('.zip', ''), format='zip', root_dir=folder_to_zip)\n\nprint(f\"Folder '{folder_to_zip}' has been zipped as '{output_zip_file}'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import imageio\nimport numpy as np\nimport os\nfrom scipy.ndimage import binary_fill_holes, binary_dilation\nimport matplotlib.pyplot as plt\n\n# Define the input and output directories\ninput_dir = '/kaggle/working/Mask_Norm'\noutput_dir = '/kaggle/working/Mask_Norm_Enh_Filled_FInal'\n\n# Ensure the output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Process each image in the input directory\nfor filename in os.listdir(input_dir):\n    if filename.endswith('.png'):  # Adjust the extension if needed\n        # Step 1: Read the mask image\n        mask_image_path = os.path.join(input_dir, filename)\n        mask_image = imageio.imread(mask_image_path)\n\n        # Step 2: Convert to binary array (if not already binary)\n        binary_mask = mask_image > 0  # Adjust the threshold as needed\n\n        # Step 3: Fill holes in the binary mask\n        filled_mask = binary_fill_holes(binary_mask)\n\n        # Step 4: Apply binary dilation\n        dilated_mask = binary_dilation(filled_mask, iterations=5)\n\n        # Fill holes again after dilation\n        again_filled_mask = binary_fill_holes(dilated_mask)\n\n        # Step 5: Save the processed mask\n        output_image_path = os.path.join(output_dir, filename)\n        imageio.imwrite(output_image_path, (again_filled_mask * 255).astype(np.uint8))\n\n# Display the original, filled, dilated, and again filled masks for the last processed image\nplt.figure(figsize=(20, 5))\n\nplt.subplot(1, 4, 1)\nplt.title('Original Mask')\nplt.imshow(mask_image, cmap='gray')\n\nplt.subplot(1, 4, 2)\nplt.title('Filled Mask')\nplt.imshow(filled_mask, cmap='gray')\n\nplt.subplot(1, 4, 3)\nplt.title('Dilated Mask')\nplt.imshow(dilated_mask, cmap='gray')\n\nplt.subplot(1, 4, 4)\nplt.title('Again Filled Mask')\nplt.imshow(again_filled_mask, cmap='gray')\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Specify the folder you want to zip\nfolder_to_zip = '/kaggle/working/Mask_Norm_Enh_Filled_FInal'\n\n# Specify the name and path for the output zip file\noutput_zip_file = '/kaggle/working/Mask_Norm_Enh_Filled_FInal.zip'\n\n# Create the zip archive\nshutil.make_archive(base_name=output_zip_file.replace('.zip', ''), format='zip', root_dir=folder_to_zip)\n\nprint(f\"Folder '{folder_to_zip}' has been zipped as '{output_zip_file}'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport os\n\ndef zip_folder(folder_path, output_zip):\n    \"\"\"\n    Zip the contents of a folder (recursively) into a zip file.\n    \n    Args:\n    - folder_path (str): Path to the folder to be zipped.\n    - output_zip (str): Path to the output zip file.\n    \"\"\"\n    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(folder_path):\n            for file in files:\n                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder_path))\n\n# Example usage:\nfolder_to_zip = '/kaggle/working/jsrt'\noutput_zip_file = '/kaggle/working/jsrtshenmonenh.zip'\n\nzip_folder(folder_to_zip, output_zip_file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
